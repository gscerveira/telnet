{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - Setup: Clone repo and install dependencies\n",
    "# Mount Google Drive for output storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "\n",
    "# Create output directory on Drive\n",
    "TELNET_DATADIR = '/content/drive/MyDrive/telnet_data'\n",
    "os.makedirs(TELNET_DATADIR, exist_ok=True)\n",
    "os.makedirs(f'{TELNET_DATADIR}/data/models', exist_ok=True)\n",
    "os.makedirs(f'{TELNET_DATADIR}/shapefiles', exist_ok=True)\n",
    "os.makedirs(f'{TELNET_DATADIR}/results', exist_ok=True)\n",
    "os.environ['TELNET_DATADIR'] = TELNET_DATADIR\n",
    "print(f\"TELNET_DATADIR set to: {TELNET_DATADIR}\")\n",
    "\n",
    "# Clone the repo\n",
    "%cd /content\n",
    "!rm -rf telnet\n",
    "!git clone https://github.com/gscerveira/telnet.git\n",
    "%cd telnet\n",
    "\n",
    "# Install uv for fast package management\n",
    "!pip install -q uv\n",
    "\n",
    "# Install dependencies\n",
    "!uv pip install --system -q -r docker/requirements.txt\n",
    "!uv pip install --system -q gcsfs s3fs geopandas rioxarray\n",
    "\n",
    "print(\"\\nDependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 - Verify GPU\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU available! Switch to a GPU runtime.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 - Test ARCO ERA5 Access (quick connectivity check)\n",
    "%cd /content/telnet\n",
    "\n",
    "print(\"Testing ARCO ERA5 access...\")\n",
    "import gcsfs\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(token='anon')\n",
    "path = 'gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3'\n",
    "files = fs.ls(path)[:5]\n",
    "print(\"Connection successful! Found files:\")\n",
    "for f in files:\n",
    "    print(f\"  {f}\")\n",
    "print(\"\\nARCO ERA5 is accessible.\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Cell 3.5 - Setup CDS API credentials for ERA5 download\n# You need a free account at https://cds.climate.copernicus.eu/\n# Get your API key from: https://cds.climate.copernicus.eu/how-to-api\n\nimport os\n\n# INSTRUCTIONS:\n# 1. Register for a free account at https://cds.climate.copernicus.eu/\n# 2. Go to https://cds.climate.copernicus.eu/how-to-api to get your API key\n# 3. Replace 'YOUR-API-KEY-HERE' with your actual API key\n\nCDS_URL = \"https://cds.climate.copernicus.eu/api\"\nCDS_KEY = \"YOUR-API-KEY-HERE\"  # <-- Replace with your API key from CDS website\n\n# Create .cdsapirc file\ncdsapirc_content = f\"\"\"url: {CDS_URL}\nkey: {CDS_KEY}\n\"\"\"\n\ncdsapirc_path = os.path.expanduser('~/.cdsapirc')\nwith open(cdsapirc_path, 'w') as f:\n    f.write(cdsapirc_content)\n\nprint(\"CDS API credentials configured.\")\nprint(f\"Config file written to: {cdsapirc_path}\")\nprint()\nif CDS_KEY == \"YOUR-API-KEY-HERE\":\n    print(\"⚠️  WARNING: You need to replace 'YOUR-API-KEY-HERE' with your actual API key!\")\n    print(\"   Register at: https://cds.climate.copernicus.eu/\")\n    print(\"   Get API key: https://cds.climate.copernicus.eu/how-to-api\")\nelse:\n    print(\"✓ API key configured. Ready to download ERA5 data.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 4 - Download ERSSTv5, ERA5, and Maranhao shapefile\n%cd /content/telnet\nimport os\nos.environ['TELNET_DATADIR'] = '/content/drive/MyDrive/telnet_data'\n\n# Download ERSSTv5\nprint(\"=\" * 60)\nprint(\"  Downloading ERSSTv5 sea surface temperature data...\")\nprint(\"=\" * 60)\nfrom download_preprocess_data import download_ersstv5\ndownload_ersstv5('1940-01-01', '2025-12-01')\n\n# Download ERA5 via CDS API (requires .cdsapirc credentials)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"  Downloading ERA5 (u10, v10, geopotential) via CDS API...\")\nprint(\"  This may take 30-60 minutes for the first download.\")\nprint(\"=\" * 60)\n!python download_preprocess_data.py -idate 194001 -fdate 202512\n\n# Download shapefile\nprint(\"\\n\" + \"=\" * 60)\nprint(\"  Downloading Maranhao shapefile...\")\nprint(\"=\" * 60)\n!python download_maranhao_shapefile.py\n\nprint(\"\\nDownloads complete!\")"
  },
  {
   "cell_type": "code",
   "source": "# Cell 4.5 - Preprocess ERA5 files for climate indices\n# Run this after downloading ERA5 data from CDS\n# This creates the preprocessed files needed by compute_climate_indices.py\n\nimport xarray as xr\nimport numpy as np\nimport os\n\nera5_dir = '/content/drive/MyDrive/telnet_data/era5'\n\n# Target 2-degree grid (global)\nlat2interp = np.arange(-88., 90., 2.0)[::-1]\nlon2interp = np.arange(0., 360., 2.0)\n\n# Process u10\nprint(\"Processing u10...\")\nds = xr.open_dataset(f'{era5_dir}/era5_u10_1940-2025.nc')\nds = ds.interp(latitude=lat2interp, longitude=lon2interp, method='linear')\nds = ds.rename({'valid_time': 'time', 'latitude': 'lat', 'longitude': 'lon'})\nds.to_netcdf(f'{era5_dir}/era5_u10_1940-present_preprocessed.nc')\nprint(\"  Saved era5_u10_1940-present_preprocessed.nc\")\n\n# Process v10\nprint(\"Processing v10...\")\nds = xr.open_dataset(f'{era5_dir}/era5_v10_1940-2025.nc')\nds = ds.interp(latitude=lat2interp, longitude=lon2interp, method='linear')\nds = ds.rename({'valid_time': 'time', 'latitude': 'lat', 'longitude': 'lon'})\nds.to_netcdf(f'{era5_dir}/era5_v10_1940-present_preprocessed.nc')\nprint(\"  Saved era5_v10_1940-present_preprocessed.nc\")\n\n# Process geopotential (combine 3 levels, convert to height)\nprint(\"Processing geopotential height...\")\nds_500 = xr.open_dataset(f'{era5_dir}/era5_hgt_500_1940-2025.nc')\nds_700 = xr.open_dataset(f'{era5_dir}/era5_hgt_700_1940-2025.nc')\nds_1000 = xr.open_dataset(f'{era5_dir}/era5_hgt_1000_1940-2025.nc')\n\n# Convert geopotential to height (divide by g=9.80665)\ng = 9.80665\nds_500['height'] = ds_500['z'] / g\nds_700['height'] = ds_700['z'] / g\nds_1000['height'] = ds_1000['z'] / g\n\n# Combine levels\nds = xr.concat([ds_500['height'], ds_700['height'], ds_1000['height']], dim='pressure_level')\nds = ds.assign_coords(pressure_level=[500, 700, 1000])\nds = ds.to_dataset(name='height')\n\nds = ds.interp(latitude=lat2interp, longitude=lon2interp, method='linear')\nds = ds.rename({'valid_time': 'time', 'latitude': 'lat', 'longitude': 'lon'})\nds.to_netcdf(f'{era5_dir}/era5_hgt_1940-present_preprocessed.nc')\nprint(\"  Saved era5_hgt_1940-present_preprocessed.nc\")\n\nprint(\"\\nDone! Ready to run climate indices (Cell 5).\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 - Compute Climate Indices (from ERSSTv5 data)\n",
    "%cd /content/telnet\n",
    "import os\n",
    "os.environ['TELNET_DATADIR'] = '/content/drive/MyDrive/telnet_data'\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  Computing climate indices from ERSSTv5...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "!python compute_climate_indices.py --finaldate 202512\n",
    "\n",
    "print(\"\\nClimate indices computed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 - Feature Pre-Selection (PMI ranking)\n",
    "# This uses ARCO ERA5 data - streams from GCS (fast!)\n",
    "%cd /content/telnet\n",
    "import os\n",
    "os.environ['TELNET_DATADIR'] = '/content/drive/MyDrive/telnet_data'\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  Running feature pre-selection (PMI ranking)\")\n",
    "print(\"  Using ARCO ERA5 data from GCS...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use fewer samples for faster testing (100 is good, 1000 for production)\n",
    "N_SAMPLES = 100\n",
    "\n",
    "!python feature_pre_selection.py -n {N_SAMPLES}\n",
    "\n",
    "# Copy results to Drive\n",
    "import shutil\n",
    "src = '/content/telnet/data/models/final_feats.txt'\n",
    "dst = '/content/drive/MyDrive/telnet_data/data/models/final_feats.txt'\n",
    "if os.path.exists(src):\n",
    "    shutil.copy(src, dst)\n",
    "    print(f\"Copied final_feats.txt to Drive\")\n",
    "\n",
    "src_seeds = '/content/telnet/data/seeds_pmi.txt'\n",
    "dst_seeds = '/content/drive/MyDrive/telnet_data/data/seeds_pmi.txt'\n",
    "if os.path.exists(src_seeds):\n",
    "    shutil.copy(src_seeds, dst_seeds)\n",
    "    print(f\"Copied seeds_pmi.txt to Drive\")\n",
    "\n",
    "print(\"\\nFeature pre-selection complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 - Model Selection (GPU grid search)\n",
    "%cd /content/telnet\n",
    "import os\n",
    "os.environ['TELNET_DATADIR'] = '/content/drive/MyDrive/telnet_data'\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  Running model selection (hyperparameter grid search)\")\n",
    "print(\"  This is GPU-intensive and will take 2-3 hours...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "!chmod +x model_selection.sh\n",
    "!./model_selection.sh 100 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 - Model Testing (final training with best hyperparameters)\n",
    "%cd /content/telnet\n",
    "import os\n",
    "os.environ['TELNET_DATADIR'] = '/content/drive/MyDrive/telnet_data'\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  Running model testing (final training)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "!python model_testing.py -n 100 -c 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 - Generate Forecasts (4 quarterly initializations)\n",
    "%cd /content/telnet\n",
    "import os\n",
    "os.environ['TELNET_DATADIR'] = '/content/drive/MyDrive/telnet_data'\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  Generating seasonal forecasts...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "!chmod +x generate_forecast.sh\n",
    "\n",
    "init_dates = ['202501', '202504', '202507', '202510']\n",
    "\n",
    "for init_date in init_dates:\n",
    "    print(f\"\\n=== Forecast for {init_date} ===\")\n",
    "    !./generate_forecast.sh {init_date} 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 - Extract Maranhao Region from forecasts\n",
    "%cd /content/telnet\n",
    "import os\n",
    "import glob\n",
    "\n",
    "os.environ['TELNET_DATADIR'] = '/content/drive/MyDrive/telnet_data'\n",
    "DATADIR = os.environ['TELNET_DATADIR']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  Extracting Maranhao region from forecasts...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "init_dates = ['202501', '202504', '202507', '202510']\n",
    "\n",
    "for init_date in init_dates:\n",
    "    results_dir = f'{DATADIR}/results/{init_date}'\n",
    "    if os.path.exists(results_dir):\n",
    "        for f in glob.glob(f'{results_dir}/*.nc'):\n",
    "            basename = os.path.basename(f)\n",
    "            if not basename.startswith('maranhao_'):\n",
    "                output = f'{results_dir}/maranhao_{basename}'\n",
    "                !python extract_maranhao.py \"{f}\" \"{output}\" --shapefile-dir {DATADIR}/shapefiles\n",
    "                print(f\"Extracted: {output}\")\n",
    "\n",
    "print(\"\\nMaranhao extraction complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11 - View Results Summary\n",
    "import os\n",
    "import glob\n",
    "\n",
    "DATADIR = '/content/drive/MyDrive/telnet_data'\n",
    "init_dates = ['202501', '202504', '202507', '202510']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  ARCO ERA5 Workflow Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"Results saved to Google Drive:\")\n",
    "print(f\"  {DATADIR}/results/\")\n",
    "print()\n",
    "\n",
    "for init_date in init_dates:\n",
    "    results_dir = f'{DATADIR}/results/{init_date}'\n",
    "    if os.path.exists(results_dir):\n",
    "        files = os.listdir(results_dir)\n",
    "        nc_files = [f for f in files if f.endswith('.nc')]\n",
    "        print(f\"{init_date}: {len(nc_files)} forecast files\")\n",
    "        for f in sorted(nc_files)[:3]:\n",
    "            print(f\"  - {f}\")\n",
    "        if len(nc_files) > 3:\n",
    "            print(f\"  ... and {len(nc_files) - 3} more\")\n",
    "    else:\n",
    "        print(f\"{init_date}: No results yet\")\n",
    "\n",
    "print()\n",
    "print(\"Feature ranking saved to:\")\n",
    "print(f\"  {DATADIR}/data/models/final_feats.txt\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}